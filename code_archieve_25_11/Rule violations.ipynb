{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import operator\n",
    "import itertools\n",
    "\n",
    "import numpy\n",
    "import sklearn.ensemble\n",
    "import sklearn.linear_model\n",
    "import sklearn.feature_extraction\n",
    "import pandas\n",
    "import html\n",
    "#import raha\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_CONSTRAINTS = {\n",
    "            \"hospital\": {\n",
    "                \"functions\": [[\"city\", \"zip\"], [\"city\", \"county\"], [\"zip\", \"city\"], [\"zip\", \"state\"], [\"zip\", \"county\"],\n",
    "                              [\"county\", \"state\"]]\n",
    "               \n",
    "            },\n",
    "            \"flights\": {\n",
    "                \"functions\": [[\"flight\", \"act_dep_time\"], [\"flight\", \"sched_arr_time\"], [\"flight\", \"act_arr_time\"],\n",
    "                              [\"flight\", \"sched_dep_time\"]]\n",
    "            \n",
    "            },\n",
    "    \"tax\":{\n",
    "        \n",
    "        \"functions\":[['zip','city'],['zip','state'],['area_code','state']]\n",
    "    }\n",
    "}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"tax\"\n",
    "dataset_dictionary = {\n",
    "        \"name\": dataset_name,\n",
    "        \"path\": os.path.abspath(os.path.join( \"datasets\", dataset_name, \"dirty.csv\")),\n",
    "        \"clean_path\": os.path.abspath(os.path.join(\"datasets\", dataset_name, \"clean.csv\"))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_normalizer(value):\n",
    "        \"\"\"\n",
    "        This method takes a value and minimally normalizes it.\n",
    "        \"\"\"\n",
    "        value = html.unescape(value)\n",
    "        value = re.sub(\"[\\t\\n ]+\", \" \", value, re.UNICODE)\n",
    "        value = value.strip(\"\\t\\n \")\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_dataset(dataset_path):\n",
    "        \"\"\"\n",
    "        This method reads a dataset from a csv file path.\n",
    "        \"\"\"\n",
    "        dataframe = pandas.read_csv(dataset_path, sep=\",\", header=\"infer\", encoding=\"utf-8\", dtype=str,\n",
    "                                    keep_default_na=False, low_memory=False).applymap(value_normalizer)\n",
    "        return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = dataset_dictionary[\"name\"]\n",
    "path = dataset_dictionary[\"path\"]\n",
    "dataframe = read_csv_dataset(dataset_dictionary[\"path\"])\n",
    "if \"clean_path\" in dataset_dictionary:\n",
    "    has_ground_truth = True\n",
    "    clean_path = dataset_dictionary[\"clean_path\"]\n",
    "    clean_dataframe = read_csv_dataset(dataset_dictionary[\"clean_path\"])\n",
    "if \"repaired_path\" in dataset_dictionary:\n",
    "    has_been_repaired = True\n",
    "    repaired_path = dataset_dictionary[\"repaired_path\"]\n",
    "    repaired_dataframe = read_csv_dataset(dataset_dictionary[\"repaired_path\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_error=calculate_total_error_realworld(clean_dataframe, dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121219"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library for fasttext\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import fasttext\n",
    "from fasttext import train_unsupervised\n",
    "import gensim\n",
    "from gensim.models import FastText\n",
    "import ast\n",
    "########################################\n",
    "#library for parsing and extracting wiki revision data\n",
    "import os\n",
    "import re\n",
    "import io\n",
    "import sys\n",
    "import math\n",
    "import json\n",
    "import html\n",
    "import pickle\n",
    "import difflib\n",
    "import unicodedata\n",
    "import bs4\n",
    "import bz2\n",
    "import py7zr\n",
    "import numpy\n",
    "import mwparserfromhell\n",
    "import libarchive.public\n",
    "#import dataset\n",
    "import wikitextparser as wtp\n",
    "from pprint import pprint\n",
    "from wikitextparser import remove_markup, parse\n",
    "import datetime\n",
    "from pandas import DataFrame\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import logging\n",
    "from datasets import *\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_fds=[['flight','act_dep_time'],['flight','sched_dep_time'],['flight','sched_arr_time'],['flight','act_arr_time']]\n",
    "flight_fds_att=['flight','act_dep_time','sched_dep_time','sched_arr_time','act_arr_time']\n",
    "domain_dirty_col=['address_1','city','state','county','state','area_code']\n",
    "domain_clean_col=['Address1','City','State','CountyName','city','state','area_code']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_fds=[['city','state','area_code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain_data=prepare_dataset_for_retrain_realworld(clean_dataframe, dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrain_data[['flight', 'act_dep_time']]\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['city', 'state', 'area_code']\n",
      "0 800\n",
      "121219 800 0\n",
      "(0.0, 0.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "score=error_correction_fasttext_with_retrain_realworld_fds_new(\"Fasttext_D_F\",retrain_data,\"flights\",flight_fds,total_error, dataframe, clean_dataframe,domain_dirty_col,domain_clean_col)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score #try with whole attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText(size=4, window=3, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.0'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_correction_fasttext_with_retrain_realworld_fds_new(model_type,data_for_retrain,dataset_name,fds_set,total_error, dirty_data, clean_data,domain_dirty_col,domain_clean_col):\n",
    "        #total_error=0\n",
    "        total_error_to_repaired=0\n",
    "        total_repaired=0\n",
    "        dirty_data=data_for_retrain\n",
    "        try:\n",
    "            if model_type==\"Fasttext_G_F\":\n",
    "                model_fasttext=FastText.load(\"model/Fasttext_All_Domain.w2v\")\n",
    "            if model_type==\"Fasttext_D_F\":\n",
    "                model_fasttext=FastText.load(\"model/Fasttext_Location_Domain.w2v\")\n",
    "        except Exception as e:\n",
    "            print('Model Error: ',str(e))\n",
    "        err_fds_con=[]\n",
    "        for fds in  fds_set:\n",
    "            print(fds)\n",
    "            data_for_retrain=dirty_data #retrain the whole datasest\n",
    "            train_data_rows=[]\n",
    "            try:         \n",
    "                data_for_retrain=data_for_retrain.values.tolist()\n",
    "                for row in data_for_retrain:\n",
    "                    #row = list(map(str, row))\n",
    "                    row=list(filter(None, row))\n",
    "                    if 'None' in row:\n",
    "                        continue\n",
    "                    else:\n",
    "                        train_data_rows.append(row)\n",
    "                if train_data_rows:\n",
    "                   # print(train_data_rows)\n",
    "                    if train_data_rows:\n",
    "                        model_fasttext = FastText(train_data_rows, min_count=1, workers=8, iter=500, window=len(train_data_rows[0]))\n",
    "                        #model = Word2Vec(train_data_rows, sg=1, min_count=1, workers=8, iter=1000, window=2)\n",
    "                        #model_fasttext.build_vocab(train_data_rows, update=True)\n",
    "                        #model_fasttext=(vector_size=4, window=3, min_count=1, sentences=train_data_rows, epochs=10)\n",
    "                        #model_fasttext.train(sentences=train_data_rows, total_examples = len(train_data_rows), epochs=5)\n",
    "            except Exception as e:\n",
    "                print(\"Exception from spell model : \", str(e))\n",
    "            err_fds=[]\n",
    "            for col_fds in fds:\n",
    "                if col_fds in err_fds_con:\n",
    "                    continue\n",
    "                else:\n",
    "                    err_fds_con.append(col_fds)\n",
    "                    err_fds.append(col_fds)\n",
    "            if model_type==\"Fasttext_G_F\":\n",
    "                error_correction=prepare_testing_datasets_real_world_data_error(dirty_data,clean_data,\"fds\",dataset_name,fds)\n",
    "            else:\n",
    "                error_correction=prepare_domain_testing_datasets_real_world_data_error(dirty_data,clean_data,\"fds\",dataset_name,domain_dirty_col,domain_clean_col,fds)\n",
    "            for error_value, actual_value,want_to_clean,index in zip(error_correction['error'],error_correction['actual'],error_correction['want_to_clean'],error_correction['index']):\n",
    "                try:\n",
    "                    dirty_row=[]\n",
    "                    if fds:\n",
    "                        for fds_col in fds:\n",
    "                            dirty_row.append(str(dirty_data.at[index, fds_col]))\n",
    "                    if dirty_row:\n",
    "                        #dirty_row = list(map(str, dirty_row))\n",
    "                        dirty_row=list(filter(None, dirty_row))\n",
    "                        if error_value:\n",
    "                            dirty_row.remove(error_value)\n",
    "                    #total_error=total_error+1\n",
    "                    want_to_clean=str(want_to_clean)\n",
    "                   # print(dirty_row, error_value)\n",
    "                    if want_to_clean==\"1\" and len(error_value)<20 and total_error_to_repaired<10000:\n",
    "                        total_error_to_repaired=total_error_to_repaired+1\n",
    "                        if fds and dirty_row:\n",
    "                            similar_value=model_fasttext.most_similar(positive=dirty_row, negative=[error_value])\n",
    "                            #similar_value=model_fasttext.most_similar(dirty_row[0])\n",
    "                            #R_Value=model.wv.most_similar(positive=dirty_row)\n",
    "                        else:\n",
    "                            similar_value=model_fasttext.most_similar(error_value)\n",
    "                        #print(similar_value)\n",
    "                        #R_Value=model.wv.most_similar(positive=dirty_row)\n",
    "                        #print(R_Value)\n",
    "                        #a=R_Value[0]\n",
    "                        #b,c=a\n",
    "                        #first=b\n",
    "                        first,b=similar_value[0]\n",
    "                        actual_value=str(actual_value)               \n",
    "                        first=first.strip()\n",
    "                        actual_value=actual_value.strip()\n",
    "                        #print(first,actual_value)\n",
    "                        if first==actual_value:\n",
    "                            total_repaired=total_repaired+1\n",
    "                except Exception as e:\n",
    "                    print('Error correction model: ',str(e))\n",
    "            print(total_repaired,total_error_to_repaired)\n",
    "        print(total_error,total_error_to_repaired,total_repaired )\n",
    "        if total_error_to_repaired>0:\n",
    "            p,r,f=evaluate_model(total_error,total_error_to_repaired,total_repaired)\n",
    "        else:\n",
    "            p,r,f=\"Invalid\", \"Invalid\", \"Invalid\"\n",
    "        return p,r,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ar_error_correction_fasttext_with_retrain_realworld_fds_new(model_type,data_for_retrain,dataset_name,fds_set,total_error, dirty_data, clean_data,domain_dirty_col,domain_clean_col):\n",
    "        #total_error=0\n",
    "        total_error_to_repaired=0\n",
    "        total_repaired=0\n",
    "        dirty_data=data_for_retrain\n",
    "        try:\n",
    "            if model_type==\"Fasttext_G_F\":\n",
    "                model_fasttext=FastText.load(\"model/Fasttext_All_Domain.w2v\")\n",
    "            if model_type==\"Fasttext_D_F\":\n",
    "                model_fasttext=FastText.load(\"model/Fasttext_Location_Domain.w2v\")\n",
    "        except Exception as e:\n",
    "            print('Model Error: ',str(e))\n",
    "        err_fds_con=[]\n",
    "        for fds in  fds_set:\n",
    "            print(fds)\n",
    "            data_for_retrain=dirty_data #retrain the whole datasest\n",
    "            train_data_rows=[]\n",
    "            try:         \n",
    "                data_for_retrain=data_for_retrain.values.tolist()\n",
    "                for row in data_for_retrain:\n",
    "                    #row = list(map(str, row))\n",
    "                    row=list(filter(None, row))\n",
    "                    if 'None' in row:\n",
    "                        continue\n",
    "                    else:\n",
    "                        train_data_rows.append(row)\n",
    "                if train_data_rows:\n",
    "                   # print(train_data_rows)\n",
    "                    if train_data_rows:\n",
    "                        model_fasttext = FastText(train_data_rows, min_count=1, workers=8, iter=500, window=len(train_data_rows[0]))\n",
    "                        #model = Word2Vec(train_data_rows, sg=1, min_count=1, workers=8, iter=1000, window=2)\n",
    "                        #model_fasttext.build_vocab(train_data_rows, update=True)\n",
    "                        #model_fasttext=(vector_size=4, window=3, min_count=1, sentences=train_data_rows, epochs=10)\n",
    "                        #model_fasttext.train(sentences=train_data_rows, total_examples = len(train_data_rows), epochs=5)\n",
    "            except Exception as e:\n",
    "                print(\"Exception from spell model : \", str(e))\n",
    "            err_fds=[]\n",
    "            for col_fds in fds:\n",
    "                if col_fds in err_fds_con:\n",
    "                    continue\n",
    "                else:\n",
    "                    err_fds_con.append(col_fds)\n",
    "                    err_fds.append(col_fds)\n",
    "            if model_type==\"Fasttext_G_F\":\n",
    "                error_correction=prepare_testing_datasets_real_world_data_error(dirty_data,clean_data,\"fds\",dataset_name,err_fds)\n",
    "            else:\n",
    "                error_correction=prepare_domain_testing_datasets_real_world_data_error(dirty_data,clean_data,\"fds\",dataset_name,domain_dirty_col,domain_clean_col,err_fds)\n",
    "            for error_value, actual_value,want_to_clean,index in zip(error_correction['error'],error_correction['actual'],error_correction['want_to_clean'],error_correction['index']):\n",
    "                try:\n",
    "                    dirty_row=[]\n",
    "                    if fds:\n",
    "                        for fds_col in fds:\n",
    "                            dirty_row.append(str(dirty_data.at[index, fds_col]))\n",
    "                    if dirty_row:\n",
    "                        #dirty_row = list(map(str, dirty_row))\n",
    "                        dirty_row=list(filter(None, dirty_row))\n",
    "                        if error_value:\n",
    "                            dirty_row.remove(error_value)\n",
    "                    #total_error=total_error+1\n",
    "                    want_to_clean=str(want_to_clean)\n",
    "                   # print(dirty_row, error_value)\n",
    "                    if want_to_clean==\"1\" and len(error_value)<20 and total_error_to_repaired<10000:\n",
    "                        total_error_to_repaired=total_error_to_repaired+1\n",
    "                        if fds and dirty_row:\n",
    "                            similar_value=model_fasttext.most_similar(positive=dirty_row, negative=[error_value])\n",
    "                            #similar_value=model_fasttext.most_similar(dirty_row[0])\n",
    "                            #R_Value=model.wv.most_similar(positive=dirty_row)\n",
    "                        else:\n",
    "                            similar_value=model_fasttext.most_similar(error_value)\n",
    "                        #print(similar_value)\n",
    "                        #R_Value=model.wv.most_similar(positive=dirty_row)\n",
    "                        #print(R_Value)\n",
    "                        #a=R_Value[0]\n",
    "                        #b,c=a\n",
    "                        #first=b\n",
    "                        first,b=similar_value[0]\n",
    "                        actual_value=str(actual_value)               \n",
    "                        first=first.strip()\n",
    "                        actual_value=actual_value.strip()\n",
    "                        #print(first,actual_value)\n",
    "                        if first==actual_value:\n",
    "                            total_repaired=total_repaired+1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print('Error correction model: ',str(e))\n",
    "            print(total_repaired,total_error_to_repaired)\n",
    "        print(total_error,total_error_to_repaired,total_repaired )\n",
    "        if total_error_to_repaired>0:\n",
    "            p,r,f=evaluate_model(total_error,total_error_to_repaired,total_repaired)\n",
    "        else:\n",
    "            p,r,f=\"Invalid\", \"Invalid\", \"Invalid\"\n",
    "        return p,r,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model (total_error, total_error_to_repair, total_correction):\n",
    "        if total_error_to_repair==0:\n",
    "            precision=0.00\n",
    "        else:\n",
    "            precision=total_correction/total_error_to_repair\n",
    "            precision=round(precision,2)\n",
    "        if total_error==0:\n",
    "            recall=0.00\n",
    "        else:\n",
    "            recall=total_correction/total_error\n",
    "            recall=round(recall,2)\n",
    "        if (precision+recall)==0:\n",
    "            f_score=0.00\n",
    "        else:\n",
    "            f_score=(2 * precision * recall) / (precision + recall) \n",
    "            f_score=round(f_score,2)     \n",
    "        return precision, recall,f_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
